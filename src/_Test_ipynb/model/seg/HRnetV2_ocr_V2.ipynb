{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch._utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.__version__.startswith('0'):\n",
    "    from .sync_bn.inplace_abn.bn import InPlaceABNSync\n",
    "    BatchNorm2d = functools.partial(InPlaceABNSync, activation='none')\n",
    "    BatchNorm2d_class = InPlaceABNSync\n",
    "    relu_inplace = False\n",
    "else:\n",
    "    BatchNorm2d_class = BatchNorm2d = torch.nn.BatchNorm2d\n",
    "    relu_inplace = True\n",
    "\n",
    "ALIGN_CORNERS = True\n",
    "BN_MOMENTUM = 0.1\n",
    "logger = logging.getLogger(__name__)\n",
    "ALIGN_CORNERS = True\n",
    "BN_MOMENTUM = 0.1\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModuleHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def BNReLU(num_features, bn_type=None, **kwargs):\n",
    "        return nn.Sequential(\n",
    "            BatchNorm2d(num_features, **kwargs),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def BatchNorm2d(*args, **kwargs):\n",
    "        return BatchNorm2d\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class SpatialGather_Module(nn.Module):\n",
    "    \"\"\"\n",
    "        Aggregate the context features according to the initial \n",
    "        predicted probability distribution.\n",
    "        Employ the soft-weighted method to aggregate the context.\n",
    "    \"\"\"\n",
    "    def __init__(self, cls_num=0, scale=1):\n",
    "        super(SpatialGather_Module, self).__init__()\n",
    "        self.cls_num = cls_num\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, feats, probs):\n",
    "        batch_size, c, h, w = probs.size(0), probs.size(1), probs.size(2), probs.size(3)\n",
    "        probs = probs.view(batch_size, c, -1)\n",
    "        feats = feats.view(batch_size, feats.size(1), -1)\n",
    "        feats = feats.permute(0, 2, 1) # batch x hw x c \n",
    "        probs = F.softmax(self.scale * probs, dim=2)# batch x k x hw\n",
    "        ocr_context = torch.matmul(probs, feats)\\\n",
    "        .permute(0, 2, 1).unsqueeze(3)# batch x k x c\n",
    "        return ocr_context\n",
    "\n",
    "\n",
    "class _ObjectAttentionBlock(nn.Module):\n",
    "    '''\n",
    "    The basic implementation for object context block\n",
    "    Input:\n",
    "        N X C X H X W\n",
    "    Parameters:\n",
    "        in_channels       : the dimension of the input feature map\n",
    "        key_channels      : the dimension after the key/query transform\n",
    "        scale             : choose the scale to downsample the input feature maps (save memory cost)\n",
    "        bn_type           : specify the bn type\n",
    "    Return:\n",
    "        N X C X H X W\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(_ObjectAttentionBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.in_channels = in_channels\n",
    "        self.key_channels = key_channels\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(scale, scale))\n",
    "        self.f_pixel = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_object = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n",
    "        )\n",
    "        self.f_up = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.key_channels, out_channels=self.in_channels,\n",
    "                kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(self.in_channels, bn_type=bn_type),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, proxy):\n",
    "        batch_size, h, w = x.size(0), x.size(2), x.size(3)\n",
    "        if self.scale > 1:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        query = self.f_pixel(x).view(batch_size, self.key_channels, -1)\n",
    "        query = query.permute(0, 2, 1)\n",
    "        key = self.f_object(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = self.f_down(proxy).view(batch_size, self.key_channels, -1)\n",
    "        value = value.permute(0, 2, 1)\n",
    "\n",
    "        sim_map = torch.matmul(query, key)\n",
    "        sim_map = (self.key_channels**-.5) * sim_map\n",
    "        sim_map = F.softmax(sim_map, dim=-1)   \n",
    "\n",
    "        # add bg context ...\n",
    "        context = torch.matmul(sim_map, value)\n",
    "        context = context.permute(0, 2, 1).contiguous()\n",
    "        context = context.view(batch_size, self.key_channels, *x.size()[2:])\n",
    "        context = self.f_up(context)\n",
    "        if self.scale > 1:\n",
    "            context = F.interpolate(input=context, size=(h, w), mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "class ObjectAttentionBlock2D(_ObjectAttentionBlock):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 scale=1, \n",
    "                 bn_type=None):\n",
    "        super(ObjectAttentionBlock2D, self).__init__(in_channels,\n",
    "                                                     key_channels,\n",
    "                                                     scale, \n",
    "                                                     bn_type=bn_type)\n",
    "\n",
    "\n",
    "class SpatialOCR_Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the OCR module:\n",
    "    We aggregate the global object representation to update the representation for each pixel.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 key_channels, \n",
    "                 out_channels, \n",
    "                 scale=1, \n",
    "                 dropout=0.1, \n",
    "                 bn_type=None):\n",
    "        super(SpatialOCR_Module, self).__init__()\n",
    "        self.object_context_block = ObjectAttentionBlock2D(in_channels, \n",
    "                                                           key_channels, \n",
    "                                                           scale, \n",
    "                                                           bn_type)\n",
    "        _in_channels = 2 * in_channels\n",
    "\n",
    "        self.conv_bn_dropout = nn.Sequential(\n",
    "            nn.Conv2d(_in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n",
    "            ModuleHelper.BNReLU(out_channels, bn_type=bn_type),\n",
    "            nn.Dropout2d(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, feats, proxy_feats):\n",
    "        context = self.object_context_block(feats, proxy_feats)\n",
    "\n",
    "        output = self.conv_bn_dropout(torch.cat([context, feats], 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * self.expansion,\n",
    "                               momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index],\n",
    "                          num_channels[branch_index] * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
    "                            momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index],\n",
    "                            num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index],\n",
    "                                num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j],\n",
    "                                  num_inchannels[i],\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  0,\n",
    "                                  bias=False),\n",
    "                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM),\n",
    "                                nn.ReLU(inplace=relu_inplace)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                elif j > i:\n",
    "                    width_output = x[i].shape[-1]\n",
    "                    height_output = x[i].shape[-2]\n",
    "                    y = y + F.interpolate(\n",
    "                        self.fuse_layers[i][j](x[j]),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse\n",
    "\n",
    "\n",
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}\n",
    "\n",
    "\n",
    "class HighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        global ALIGN_CORNERS\n",
    "        extra = config[\"MODEL\"][\"EXTRA\"]\n",
    "        super(HighResolutionNet, self).__init__()\n",
    "        ALIGN_CORNERS = config[\"MODEL\"][\"ALIGN_CORNERS\"]\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=relu_inplace)\n",
    "\n",
    "        self.stage1_cfg = extra['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion*num_channels\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        last_inp_channels = np.int(np.sum(pre_stage_channels))\n",
    "        ocr_mid_channels = config[\"MODEL\"][\"OCR\"][\"MID_CHANNELS\"]\n",
    "        ocr_key_channels = config[\"MODEL\"][\"OCR\"][\"KEY_CHANNELS\"]\n",
    "\n",
    "        self.conv3x3_ocr = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, ocr_mid_channels,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(ocr_mid_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "        )\n",
    "        self.ocr_gather_head = SpatialGather_Module(config[\"DATASET\"][\"NUM_CLASSES\"])\n",
    "\n",
    "        self.ocr_distri_head = SpatialOCR_Module(in_channels=ocr_mid_channels,\n",
    "                                                 key_channels=ocr_key_channels,\n",
    "                                                 out_channels=ocr_mid_channels,\n",
    "                                                 scale=1,\n",
    "                                                 dropout=0.05,\n",
    "                                                 )\n",
    "        self.cls_head = nn.Conv2d(\n",
    "            ocr_mid_channels, config[\"DATASET\"][\"NUM_CLASSES\"], kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Conv2d(last_inp_channels, last_inp_channels,\n",
    "                      kernel_size=1, stride=1, padding=0),\n",
    "            BatchNorm2d(last_inp_channels),\n",
    "            nn.ReLU(inplace=relu_inplace),\n",
    "            nn.Conv2d(last_inp_channels, config[\"DATASET\"][\"NUM_CLASSES\"],\n",
    "                      kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        \n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=relu_inplace)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                     block,\n",
    "                                     num_blocks,\n",
    "                                     num_inchannels,\n",
    "                                     num_channels,\n",
    "                                     fuse_method,\n",
    "                                     reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                if i < self.stage2_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition2[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                if i < self.stage3_cfg['NUM_BRANCHES']:\n",
    "                    x_list.append(self.transition3[i](y_list[i]))\n",
    "                else:\n",
    "                    x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        x = self.stage4(x_list)\n",
    "\n",
    "        # Upsampling\n",
    "        x0_h, x0_w = x[0].size(2), x[0].size(3)\n",
    "        x1 = F.interpolate(x[1], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x2 = F.interpolate(x[2], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "        x3 = F.interpolate(x[3], size=(x0_h, x0_w),\n",
    "                        mode='bilinear', align_corners=ALIGN_CORNERS)\n",
    "\n",
    "        feats = torch.cat([x[0], x1, x2, x3], 1)\n",
    "\n",
    "        out_aux_seg = []\n",
    "\n",
    "        # ocr\n",
    "        out_aux = self.aux_head(feats)\n",
    "        # compute contrast feature\n",
    "        feats = self.conv3x3_ocr(feats)\n",
    "\n",
    "        context = self.ocr_gather_head(feats, out_aux)\n",
    "        feats = self.ocr_distri_head(feats, context)\n",
    "\n",
    "        out = self.cls_head(feats)\n",
    "\n",
    "        out_aux_seg.append(out_aux)\n",
    "        out_aux_seg.append(out)\n",
    "\n",
    "        return out_aux_seg\n",
    "\n",
    "    def init_weights(self, pretrained='',):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for name, m in self.named_modules():\n",
    "            if any(part in name for part in {'cls', 'aux', 'ocr'}):\n",
    "                # print('skipped', name)\n",
    "                continue\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "            elif isinstance(m, BatchNorm2d_class):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained, map_location={'cuda:0': 'cpu'})\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k.replace('last_layer', 'aux_head').replace('model.', ''): v for k, v in pretrained_dict.items()}  \n",
    "            print(set(model_dict) - set(pretrained_dict))            \n",
    "            print(set(pretrained_dict) - set(model_dict))            \n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            # for k, _ in pretrained_dict.items():\n",
    "                # logger.info(\n",
    "                #     '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "        elif pretrained:\n",
    "            raise RuntimeError('No such file {}'.format(pretrained))\n",
    "\n",
    "\n",
    "def get_seg_model(cfg, **kwargs):\n",
    "    model = HighResolutionNet(cfg, **kwargs)\n",
    "    model.init_weights(cfg[\"MODEL\"][\"PRETRAINED\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config_path='hrnet_seg.yaml'\n",
    "with open(config_path) as f:\n",
    "    cfg = yaml.load(f)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.backbone = get_seg_model(cfg)\n",
    "        \n",
    "    #@autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        print(x[0].size())\n",
    "        x = F.interpolate(input=x[0], size=(512, 512), mode='bilinear', align_corners=True)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:475: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ocr_distri_head.object_context_block.f_object.1.0.running_var', 'ocr_distri_head.object_context_block.f_pixel.3.0.bias', 'ocr_distri_head.object_context_block.f_up.1.0.running_var', 'conv3x3_ocr.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_down.1.0.bias', 'ocr_distri_head.object_context_block.f_up.1.0.running_mean', 'aux_head.0.weight', 'ocr_distri_head.object_context_block.f_down.1.0.running_mean', 'aux_head.3.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_mean', 'ocr_distri_head.object_context_block.f_object.2.weight', 'ocr_distri_head.object_context_block.f_up.0.weight', 'ocr_distri_head.object_context_block.f_pixel.2.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_up.1.0.bias', 'ocr_distri_head.object_context_block.f_object.0.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.weight', 'ocr_distri_head.object_context_block.f_object.3.0.bias', 'ocr_distri_head.object_context_block.f_down.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_var', 'ocr_distri_head.object_context_block.f_down.1.0.num_batches_tracked', 'ocr_distri_head.conv_bn_dropout.1.0.running_mean', 'conv3x3_ocr.1.weight', 'aux_head.1.bias', 'ocr_distri_head.object_context_block.f_up.1.0.weight', 'aux_head.0.bias', 'ocr_distri_head.conv_bn_dropout.0.weight', 'aux_head.1.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.running_mean', 'ocr_distri_head.object_context_block.f_down.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_var', 'conv3x3_ocr.0.bias', 'ocr_distri_head.object_context_block.f_up.1.0.num_batches_tracked', 'conv3x3_ocr.1.running_var', 'ocr_distri_head.object_context_block.f_object.3.0.running_var', 'ocr_distri_head.object_context_block.f_object.3.0.weight', 'conv3x3_ocr.1.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.num_batches_tracked', 'cls_head.weight', 'conv3x3_ocr.0.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.bias', 'conv3x3_ocr.1.bias', 'aux_head.1.weight', 'ocr_distri_head.object_context_block.f_object.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_object.1.0.bias', 'ocr_distri_head.object_context_block.f_object.1.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_mean', 'ocr_distri_head.object_context_block.f_pixel.3.0.weight', 'ocr_distri_head.object_context_block.f_down.1.0.running_var', 'aux_head.1.running_var', 'ocr_distri_head.conv_bn_dropout.1.0.running_var', 'aux_head.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_object.3.0.running_mean', 'cls_head.bias', 'aux_head.3.bias', 'ocr_distri_head.conv_bn_dropout.1.0.bias'}\n",
      "{'incre_modules.0.0.bn1.running_var', 'downsamp_modules.0.1.running_mean', 'incre_modules.3.0.bn2.running_mean', 'incre_modules.1.0.downsample.1.weight', 'incre_modules.2.0.bn3.running_var', 'incre_modules.3.0.downsample.1.weight', 'incre_modules.0.0.bn2.running_var', 'incre_modules.1.0.bn1.weight', 'downsamp_modules.0.1.weight', 'incre_modules.3.0.bn2.bias', 'incre_modules.2.0.downsample.1.weight', 'incre_modules.1.0.bn2.bias', 'incre_modules.0.0.conv3.weight', 'incre_modules.2.0.bn1.running_var', 'classifier.weight', 'downsamp_modules.1.1.running_mean', 'incre_modules.2.0.downsample.1.running_var', 'incre_modules.3.0.conv3.weight', 'incre_modules.1.0.bn1.num_batches_tracked', 'incre_modules.0.0.downsample.1.bias', 'downsamp_modules.0.1.running_var', 'incre_modules.0.0.bn1.num_batches_tracked', 'incre_modules.3.0.bn2.num_batches_tracked', 'incre_modules.0.0.bn2.running_mean', 'incre_modules.1.0.downsample.1.bias', 'incre_modules.2.0.conv3.weight', 'incre_modules.0.0.bn3.running_var', 'incre_modules.3.0.conv2.weight', 'incre_modules.0.0.bn3.weight', 'incre_modules.1.0.conv1.weight', 'downsamp_modules.1.1.num_batches_tracked', 'final_layer.0.bias', 'final_layer.1.running_mean', 'downsamp_modules.2.1.running_mean', 'downsamp_modules.0.1.bias', 'incre_modules.3.0.bn2.running_var', 'incre_modules.1.0.bn2.num_batches_tracked', 'incre_modules.2.0.bn2.bias', 'incre_modules.1.0.bn3.num_batches_tracked', 'incre_modules.3.0.bn3.num_batches_tracked', 'incre_modules.3.0.bn3.bias', 'incre_modules.2.0.bn3.bias', 'incre_modules.2.0.downsample.1.bias', 'incre_modules.0.0.bn3.bias', 'incre_modules.2.0.conv2.weight', 'downsamp_modules.1.1.weight', 'incre_modules.0.0.downsample.1.num_batches_tracked', 'incre_modules.2.0.bn1.bias', 'incre_modules.1.0.bn2.running_var', 'incre_modules.1.0.bn2.running_mean', 'final_layer.0.weight', 'incre_modules.3.0.bn1.weight', 'incre_modules.2.0.downsample.1.running_mean', 'downsamp_modules.2.1.running_var', 'downsamp_modules.1.0.bias', 'incre_modules.0.0.bn2.weight', 'incre_modules.1.0.bn1.running_mean', 'classifier.bias', 'incre_modules.0.0.bn1.bias', 'incre_modules.0.0.bn2.num_batches_tracked', 'incre_modules.2.0.bn2.running_mean', 'downsamp_modules.2.1.weight', 'incre_modules.1.0.conv3.weight', 'incre_modules.2.0.bn2.num_batches_tracked', 'downsamp_modules.2.0.weight', 'incre_modules.0.0.bn1.weight', 'final_layer.1.running_var', 'final_layer.1.num_batches_tracked', 'incre_modules.3.0.downsample.1.running_mean', 'downsamp_modules.2.1.num_batches_tracked', 'incre_modules.1.0.bn3.running_var', 'incre_modules.0.0.downsample.1.weight', 'downsamp_modules.0.0.bias', 'incre_modules.2.0.downsample.0.weight', 'downsamp_modules.2.0.bias', 'incre_modules.0.0.downsample.0.weight', 'incre_modules.1.0.downsample.1.running_var', 'downsamp_modules.1.1.running_var', 'incre_modules.3.0.downsample.1.num_batches_tracked', 'incre_modules.1.0.bn3.running_mean', 'incre_modules.3.0.bn1.running_var', 'incre_modules.2.0.downsample.1.num_batches_tracked', 'downsamp_modules.1.1.bias', 'incre_modules.2.0.bn2.weight', 'incre_modules.0.0.bn2.bias', 'incre_modules.1.0.bn1.bias', 'incre_modules.1.0.bn1.running_var', 'incre_modules.3.0.downsample.1.running_var', 'incre_modules.3.0.bn1.num_batches_tracked', 'incre_modules.0.0.downsample.1.running_mean', 'incre_modules.3.0.bn3.running_mean', 'incre_modules.2.0.bn1.running_mean', 'downsamp_modules.0.0.weight', 'incre_modules.1.0.bn2.weight', 'incre_modules.2.0.bn1.num_batches_tracked', 'incre_modules.1.0.downsample.1.num_batches_tracked', 'incre_modules.1.0.downsample.0.weight', 'incre_modules.2.0.bn3.num_batches_tracked', 'incre_modules.1.0.bn3.weight', 'incre_modules.3.0.bn3.running_var', 'incre_modules.0.0.conv1.weight', 'incre_modules.3.0.conv1.weight', 'incre_modules.0.0.bn3.running_mean', 'incre_modules.3.0.bn2.weight', 'incre_modules.3.0.bn1.running_mean', 'incre_modules.1.0.conv2.weight', 'incre_modules.3.0.bn3.weight', 'downsamp_modules.0.1.num_batches_tracked', 'incre_modules.0.0.bn1.running_mean', 'incre_modules.2.0.bn2.running_var', 'incre_modules.2.0.conv1.weight', 'incre_modules.3.0.bn1.bias', 'incre_modules.1.0.bn3.bias', 'incre_modules.0.0.downsample.1.running_var', 'incre_modules.2.0.bn3.running_mean', 'final_layer.1.weight', 'incre_modules.3.0.downsample.0.weight', 'incre_modules.2.0.bn1.weight', 'incre_modules.1.0.downsample.1.running_mean', 'incre_modules.2.0.bn3.weight', 'final_layer.1.bias', 'downsamp_modules.2.1.bias', 'incre_modules.0.0.bn3.num_batches_tracked', 'incre_modules.3.0.downsample.1.bias', 'incre_modules.0.0.conv2.weight', 'downsamp_modules.1.0.weight'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SyncBatchNorm expected input tensor to be on GPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_89709/508412105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/segmentation/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_89709/3947814711.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#@autocast()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/segmentation/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_89709/207073612.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/segmentation/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/segmentation/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# currently only GPU input is supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SyncBatchNorm expected input tensor to be on GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: SyncBatchNorm expected input tensor to be on GPU"
     ]
    }
   ],
   "source": [
    "input = torch.rand(2, 3, 512, 512)\n",
    "model = Encoder()\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
